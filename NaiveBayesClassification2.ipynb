{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "NaiveBayesClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnsdudrla97/Naive_Bayes_classifier/blob/master/NaiveBayesClassification2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzBFSuUJ3k27",
        "colab_type": "text"
      },
      "source": [
        "<!--NAVIGATION-->\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/saskeli/x/blob/master/bayes.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n",
        "\n",
        "|                                       -                                       |                                       -                                       |                                       -                                       |\n",
        "|-------------------------------------------------------------------------------|-------------------------------------------------------------------------------|-------------------------------------------------------------------------------|\n",
        "|  [Exercise 1 (blob classification)](<#Exercise-1-(blob-classification&#41;>)  | [Exercise 2 (plant classification)](<#Exercise-2-(plant-classification&#41;>) |  [Exercise 3 (word classification)](<#Exercise-3-(word-classification&#41;>)  |\n",
        "|       [Exercise 4 (spam detection)](<#Exercise-4-(spam-detection&#41;>)       |                                                                               |                                                                               |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIS_qQN13k27",
        "colab_type": "text"
      },
      "source": [
        "## ML: Naive Bayes classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrLX66WE3k28",
        "colab_type": "text"
      },
      "source": [
        "분류는지도 학습의 한 형태입니다. 목표는 모든 데이터 포인트에 레이블을 달아주는 것입니다. 같은 라벨을 가진 포인트는 같은 클래스에 속합니다. 레이블이 두 개 이상있을 수 있습니다. 예를 들어, 생명체는 동물, 식물, 곰팡이, 고세균, 박테리아, 원생 동물 및 염색체 레이블로 (거칠게) 분류 될 수 있습니다. 데이터 포인트에는 레이블을 예측하는 데 사용할 수있는 특정 기능이 있습니다. 예를 들어 깃털이면 동물 일 가능성이 높습니다.\n",
        "\n",
        "지도 학습에서 알고리즘에는 먼저 기능과 레이블이있는 학습 데이터 세트가 제공됩니다. 그런 다음 알고리즘은 이러한 기능을 학습하고 (확률 적) 모델에 레이블을 지정합니다.이 모델은 나중에 볼 수없는 데이터의 레이블을 예측하는 데 사용할 수 있습니다.\n",
        "\n",
        "Naive Bayes 분류는 빠르고 이해하기 쉬운 분류 방법입니다. 속도는 기본 확률 분포, 즉 기능의 독립성에 대한 가정에 대한 일부 단순화로 인해 발생합니다. 그러나 특히 데이터에 충분한 기능이있는 경우 매우 강력 할 수 있습니다.\n",
        "\n",
        "각 레이블 L에 확률 분포가 있다고 가정합니다. 이 분포는 각 가능한 피처 조합 (피처 벡터)에 대한 확률을 제공합니다.\n",
        "\n",
        "$$P(features | L).$$\n",
        "\n",
        "베이지안 분류의 주요 아이디어는 의존 방향을 반대로하는 것입니다. 우리는 특징에 따라 레이블을 예측하려고합니다.\n",
        "\n",
        "$$P(L | features)$$\n",
        "\n",
        "\n",
        "$$P(L | features) = \\frac{P(features | L)P(L)}{P(features)}.$$\n",
        "\n",
        "L1 및 L2 및 관련 분포에 $ P (featrues | L1) $ 및 $ P (featrues | L2) $ 레이블을 지정해야한다고 가정 해 봅시다. 레이블이 모르는 \"featrues\"이 포함 된 데이터 요소가있는 경우 사후 확률의 비율을 사용하여 예측할 수 있습니다.\n",
        "$$\\frac{P(L1 | features)}{P(L2 | features)} = \\frac{P(features | L1)P(L1)}{P(features | L2)P(L2)}.$$\n",
        "\n",
        "비율이 1보다 크면 데이터 요소에 레이블 L1을 레이블하고 레이블이 없으면 레이블 L2를 지정합니다.\n",
        "레이블의 사전 확률 P (L1) 및 P (L2)는 레이블이있는 각 데이터 포인트에 대해 입력 데이터에서 쉽게 찾을 수 있습니다. 레이블에 지정된 기능의 확률도 마찬가지입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbpBev7I3k28",
        "colab_type": "text"
      },
      "source": [
        "먼저 가우시안 분포를 사용하여 순진 베이 즈 분류를 시연합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeJdOa1H3k29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Qhjxan3k3A",
        "colab_type": "code",
        "outputId": "0b13d26d-3c6f-46e1-97fe-6653b901c8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X,y = make_blobs(100, 2, centers=2, random_state=2, cluster_std=1.5)\n",
        "colors=np.array([\"green\", \"pink\"])\n",
        "plt.scatter(X[:, 0], X[:, 1], c=colors[y], s=50)\n",
        "for label, c in enumerate(colors):\n",
        "    plt.scatter([], [], c=c, label=str(label))\n",
        "plt.legend();\n",
        "plt.colorbar();"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLZTeW3F3k3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = GaussianNB()\n",
        "#model = MultinomialNB()\n",
        "model.fit(X, y);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBXD48kL3k3E",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes 알고리즘은 데이터에 2 개의 2 차원 가우스 분포를 적용했습니다. 평균과 분산은 이러한 분포를 완전히 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5Kvtzv13k3F",
        "colab_type": "code",
        "outputId": "128cfd29-d3f9-46bf-816f-116e59e2f9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "print(\"Means:\", model.theta_)\n",
        "print(\"Standard deviations:\", model.sigma_)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d0ecd7f4c38a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Means:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Standard deviations:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'theta_'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvfje9JX3k3H",
        "colab_type": "text"
      },
      "source": [
        "이 분포를 그려 봅시다. 먼저 origo에서 각 방향으로 표준 편차를 제공하는 타원을 그리는 도우미 함수를 정의합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVlOSgj83k3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_ellipse(ax, mu, sigma, color=\"k\", label=None):\n",
        "    \"\"\"\n",
        "    Based on\n",
        "    http://stackoverflow.com/questions/17952171/not-sure-how-to-fit-data-with-a-gaussian-python.\n",
        "    \"\"\"\n",
        "    from matplotlib.patches import Ellipse\n",
        "    # Compute eigenvalues and associated eigenvectors\n",
        "    vals, vecs = np.linalg.eigh(sigma)\n",
        "\n",
        "    # Compute \"tilt\" of ellipse using first eigenvector\n",
        "    x, y = vecs[:, 0]\n",
        "    theta = np.degrees(np.arctan2(y, x))\n",
        "\n",
        "    # Eigenvalues give length of ellipse along each eigenvector\n",
        "    w, h = 2 * np.sqrt(vals)\n",
        "\n",
        "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
        "    ellipse = Ellipse(mu, w, h, theta, color=color, label=label)  # color=\"k\")\n",
        "    ellipse.set_clip_box(ax.bbox)\n",
        "    ellipse.set_alpha(0.2)\n",
        "    ax.add_artist(ellipse)\n",
        "    return ellipse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbdg-QPw3k3J",
        "colab_type": "text"
      },
      "source": [
        "그런 다음 실제 플로팅을 수행합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1omWg2ZY3k3K",
        "colab_type": "code",
        "outputId": "6d5cd59c-1270-49b2-a02d-bb8f88be0e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "plt.figure()\n",
        "plt.xlim(-5, 5)\n",
        "plt.ylim(-15, 5)\n",
        "plot_ellipse(plt.gca(), model.theta_[0], np.identity(2)*model.sigma_[0], color=\"red\")\n",
        "plot_ellipse(plt.gca(), model.theta_[1], np.identity(2)*model.sigma_[1], color=\"blue\");"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-30a1c1151361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_ellipse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_ellipse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-otSkDz3k3M",
        "colab_type": "text"
      },
      "source": [
        "* 정확도 점수 *는 라벨을 얼마나 잘 예측했는지 측정합니다. 최대 값은 1.0입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGn6_Ikc3k3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "7d344636-2df6-4810-c55f-8a4f425539f3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_fitted = model.predict(X)\n",
        "acc=accuracy_score(y,y_fitted)\n",
        "print(\"Accuracy score is\", acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c1ac4b908e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_fitted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy score is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXo3An2q3k3P",
        "colab_type": "text"
      },
      "source": [
        "우리가 이미 본 데이터를 예측하려고 했기 때문에, 그 점수는 가능한 한 최고였는데, 그것은 놀라운 일이 아니다! 나중에 우리는 데이터를 두 부분으로 나눌 것이다: 하나는 모델을 배우는 것이고 다른 하나는 예측 기술을 시험하는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL3VJxiu3k3P",
        "colab_type": "text"
      },
      "source": [
        "### Another example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ6JrBqe3k3P",
        "colab_type": "text"
      },
      "source": [
        "Let's generate some more data using multivariate normal distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsFXFPW03k3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cov=np.array([[ 4.68, -4.32],\n",
        " [-4.32,  4.68]])\n",
        "mean1 = [0,0]\n",
        "mean2 = [0,4]\n",
        "n=500\n",
        "x1 = np.random.multivariate_normal(mean1, cov, n).T\n",
        "x2 = np.random.multivariate_normal(mean2, cov, n).T\n",
        "X=np.vstack([x1.T,x2.T])\n",
        "y=np.hstack([[0]*n, [1]*n]).T\n",
        "plt.scatter(X[:n,0], X[:n,1], color=\"red\", label=0)\n",
        "plt.scatter(X[n:,0], X[n:,1], color=\"blue\", label=1)\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj53_o1e3k3S",
        "colab_type": "text"
      },
      "source": [
        "The two clusters seem to be quite separate. Let's try naive Bayesian classification on this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Akr-_g3k3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GaussianNB()\n",
        "#model = MultinomialNB()\n",
        "model.fit(X, y);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlDXRP013k3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Means:\", model.theta_)\n",
        "print(\"Standard deviations:\", model.sigma_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-iiTF7d3k3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_fitted = model.predict(X)\n",
        "colors=np.array([\"red\", \"blue\"])\n",
        "plt.scatter(X[:,0], X[:,1], color=colors[y_fitted])\n",
        "plt.scatter([], [], color=\"red\", label=\"0\")\n",
        "plt.scatter([], [], color=\"blue\", label=\"1\")\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc=accuracy_score(y,y_fitted)\n",
        "plt.legend()\n",
        "print(\"Accuracy score is\", acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3IPAnpE3k3Z",
        "colab_type": "text"
      },
      "source": [
        "Even thought the score is quite good, we can see from the plot that the algorithm didn't have good models for the data. We can plot the models the algorithm used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13TtFzOg3k3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.xlim(-10, 10)\n",
        "plt.ylim(-15, 10)\n",
        "e1=plot_ellipse(plt.gca(), model.theta_[0], np.identity(2)*model.sigma_[0], color=\"red\", label=\"0\")\n",
        "e2=plot_ellipse(plt.gca(), model.theta_[1], np.identity(2)*model.sigma_[1], color=\"blue\", label=\"1\")\n",
        "plt.legend([e1, e2], [\"0\", \"1\"]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om4xfHJb3k3c",
        "colab_type": "text"
      },
      "source": [
        "The problem with naive Bayesian classification is that it tries to model the data using Gaussian distributions, which are aligned along the x and y axes. With this example data we would have needed Gaussian distributions which are \"tilted\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHPLOgn3k3c",
        "colab_type": "text"
      },
      "source": [
        "### Text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0PY2Njg3k3d",
        "colab_type": "text"
      },
      "source": [
        "우리는 다음 공개 포럼에 게시된 메시지 세트를 분류하려고 노력한다. 메시지는 주제별로 그룹으로 나뉘었다. 그래서 분류 테스트를 위한 데이터 세트를 준비했다. 먼저 이 데이터를 스키킷 학습을 사용하여 로드하고 메시지 범주를 인쇄합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN41kLb73k3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7d4dfc05-8f03-4f24-bb24-df753412f3fc"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "data = fetch_20newsgroups()\n",
        "data.target_names"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXQNTivr3k3g",
        "colab_type": "text"
      },
      "source": [
        "We concentrate on four message categories only. The tool `fetch_20newsgroups` allows us to easily split the data into training and testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp3tiLu23k3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = ['comp.graphics', 'rec.autos', 'sci.electronics', 'sci.crypt']\n",
        "train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "test = fetch_20newsgroups(subset='test', categories=categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAluSR7N3k3j",
        "colab_type": "text"
      },
      "source": [
        "Let's see what we got:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTKF66fM3k3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "05cf7456-6e24-4e1b-c5d1-1bb17e2bb720"
      },
      "source": [
        "print(\"Training data:\", \"Data:\", str(type(train.data)), len(train.data), \"Target:\", str(type(train.target)), len(train.target))\n",
        "print(\"Test data:\", \"Data:\", str(type(test.data)), len(test.data), \"Target\", str(type(test.data)), len(test.target))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data: Data: <class 'list'> 2364 Target: <class 'numpy.ndarray'> 2364\n",
            "Test data: Data: <class 'list'> 1574 Target <class 'list'> 1574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaJaERln3k3l",
        "colab_type": "text"
      },
      "source": [
        "데이터 세트에서 각 단어의 빈도를 기능으로 사용합니다. 즉, 데이터 세트에 별개의 단어가있는 것보다 많은 기능이 있습니다. 기능 수는 $ f $로 나타냅니다. 기능이 이제 계산되었으므로 가우스 대신 다항 분포를 사용하는 것이 합리적입니다.\n",
        "\n",
        "다항 분포를 사용하여 이러한 메시지를 모델링 해 봅시다. 각 메시지 범주에는 고유 한 배포가 있습니다. 다항 분포에는 음수가 아닌 $ f $ 매개 변수 $ \\ theta_1, \\ ldots, \\ theta_f $가 있습니다. 예를 들어, 매개 변수 $ \\ theta_3 $는이 배포판이 설명하는 범주의 메시지에 \"board\"라는 단어가 나타날 확률을 알려줍니다.\n",
        "\n",
        "scikit-learn에는 텍스트 문자열 형태의 메시지를 특징 벡터로 변환하는 클래스 'CountVectorizer'가 있습니다. 이 변환을 사용중인 모델 (다항식 순진 베이)과 통합하여 '적합'방법의 일부로 변환이 자동으로 수행되도록 할 수 있습니다. `make_pipeline` 툴을 사용하여이 통합을 달성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQaunNIL3k3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8db3fe78-c3c7-4a42-a0d8-018a447de70c"
      },
      "source": [
        "#from sklearn.feature_extraction.text import TfidfVectorizer  # an alternative feature extractor\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "#model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
        "model.fit(train.data, train.target)\n",
        "labels_fitted = model.predict(test.data)\n",
        "print(\"Accuracy score is\", accuracy_score(labels_fitted, test.target))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score is 0.920584498094028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW1dKFLx3k3n",
        "colab_type": "text"
      },
      "source": [
        "The classifier seem to work quite well! Notice that now we used separate data for testing the model.\n",
        "\n",
        "Let's have a closer look at the resulting feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcw7T2TQ3k3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "c70c2809-f385-410c-d8fe-68465186968c"
      },
      "source": [
        "vec=CountVectorizer()\n",
        "features=vec.fit_transform(train.data)\n",
        "print(\"Type of feature matrix:\", type(features))\n",
        "print(features[0,:])        # print the features of the first sample point"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of feature matrix: <class 'scipy.sparse.csr.csr_matrix'>\n",
            "  (0, 15373)\t1\n",
            "  (0, 18962)\t3\n",
            "  (0, 21852)\t5\n",
            "  (0, 9553)\t4\n",
            "  (0, 34790)\t6\n",
            "  (0, 13317)\t6\n",
            "  (0, 19099)\t1\n",
            "  (0, 16034)\t1\n",
            "  (0, 30377)\t1\n",
            "  (0, 26624)\t1\n",
            "  (0, 23858)\t1\n",
            "  (0, 20509)\t1\n",
            "  (0, 15109)\t2\n",
            "  (0, 11079)\t1\n",
            "  (0, 23854)\t2\n",
            "  (0, 32729)\t1\n",
            "  (0, 20381)\t1\n",
            "  (0, 2100)\t1\n",
            "  (0, 12580)\t1\n",
            "  (0, 18085)\t1\n",
            "  (0, 27158)\t1\n",
            "  (0, 31686)\t6\n",
            "  (0, 23118)\t1\n",
            "  (0, 25400)\t1\n",
            "  (0, 17310)\t1\n",
            "  :\t:\n",
            "  (0, 11100)\t1\n",
            "  (0, 27521)\t1\n",
            "  (0, 29104)\t1\n",
            "  (0, 5980)\t1\n",
            "  (0, 30641)\t1\n",
            "  (0, 27517)\t1\n",
            "  (0, 12577)\t1\n",
            "  (0, 25336)\t1\n",
            "  (0, 24025)\t1\n",
            "  (0, 18436)\t1\n",
            "  (0, 29505)\t1\n",
            "  (0, 29494)\t1\n",
            "  (0, 11068)\t1\n",
            "  (0, 21787)\t1\n",
            "  (0, 23460)\t1\n",
            "  (0, 34425)\t1\n",
            "  (0, 16809)\t1\n",
            "  (0, 17883)\t1\n",
            "  (0, 31398)\t1\n",
            "  (0, 34222)\t1\n",
            "  (0, 25926)\t1\n",
            "  (0, 6320)\t1\n",
            "  (0, 29697)\t1\n",
            "  (0, 19220)\t1\n",
            "  (0, 20579)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96rLo43a3k3p",
        "colab_type": "text"
      },
      "source": [
        "The feature matrix is stored in sparse format, that is, only the nonzero counts are stored. How many words were in the first message?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK8qEWb-3k3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "c101f8bf-0f3a-4dd0-e44a-69a808446761"
      },
      "source": [
        "print(\"Number of words:\", features[0,:].sum())\n",
        "col = vec.vocabulary_[\"it\"]   # Get the column of 'it' word in the feature matrix\n",
        "print(f\"Word 'it' appears in the first message {features[0, col]} times.\")\n",
        "print()\n",
        "print(train.data[0])   # Let's print the corresponding message as well\n",
        "#print(vec.get_feature_names())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words: 177\n",
            "Word 'it' appears in the first message 2 times.\n",
            "\n",
            "From: jgfoot@minerva.cis.yale.edu (Josh A. Goldfoot)\n",
            "Subject: Re: Organized Lobbying for Cryptography\n",
            "Organization: Yale University\n",
            "Lines: 21\n",
            "Distribution: inet\n",
            "Reply-To: jgfoot@minerva.cis.yale.edu\n",
            "NNTP-Posting-Host: minerva.cis.yale.edu\n",
            "X-Newsreader: TIN [version 1.1 Minerva PL9]\n",
            "\n",
            "Shaun P. Hughes (sphughes@sfsuvax1.sfsu.edu) wrote:\n",
            ": In article <1r3jgbINN35i@eli.CS.YALE.EDU> jgfoot@minerva.cis.yale.edu writes:\n",
            "[deletion]\n",
            ": >Perhaps these encryption-only types would defend the digitized porn if it\n",
            ": >was posted encrypted?\n",
            ": >\n",
            ": >These issues are not as seperable as you maintain.\n",
            ": >\n",
            "\n",
            ": Now why would anyone \"post\" anything encrypted? Encryption is only of \n",
            ": use between persons who know how to decrypt the data.\n",
            "\n",
            ": And why should I care what other people look at? \n",
            "\n",
            "I was responding to another person (Tarl Neustaedter) who held that the\n",
            "EFF wasn't the best organization to fight for crytography rights since the\n",
            "EFF also supports the right to distribute pornography over the internet,\n",
            "something some Crypto people might object to. In other words, he's\n",
            "implying that there are people who will protect any speech, just  as long\n",
            "as it is encrypted.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j4o1tA-3k3r",
        "colab_type": "text"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 1 (blob classification)</div>\n",
        "\n",
        "Write function `blob_classification` that gets feature matrix X and label vector y as parameters. It should then return the accuracy score of the prediction. Do the prediction using `GaussianNB`, and use `train_test_split` function from `sklearn` to split the dataset in to two parts: one for training and one for testing. Give parameter `random_state=0` to the splitting function so that the result is deterministic. Use training set size of 75% of the whole data.\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAQ4UhaB3k3s",
        "colab_type": "text"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 2 (plant classification)</div>\n",
        "\n",
        "Write function `plant_classification` that does the following:\n",
        "\n",
        "* loads the iris dataset using sklearn (`sklearn.datasets.load_iris`)\n",
        "* splits the data into training and testing part using the `train_test_split` function so that the training set size is 80% of the whole data (give the call also the `random_state=0` argument to make the result deterministic)\n",
        "* use Gaussian naive Bayes to fit the training data\n",
        "* predict labels of the test data\n",
        "* the function should return the accuracy score of the prediction performance (`sklearn.metrics.accuracy_score`)\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxdIoFfM3k3s",
        "colab_type": "text"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 3 (word classification)</div>\n",
        "\n",
        "This exercise can give four points at maximum!\n",
        "\n",
        "In this exercise we create a model that tries to label previously unseen words to be either Finnish or English.\n",
        "\n",
        "Part 1.\n",
        "\n",
        "Write function `get_features` that gets a one dimensional np.array, containing words, as parameter. It should return a feature matrix of shape (n, 29), where n is the number of elements of the input array. There should be one feature for each of the letters in the following alphabet: \"abcdefghijklmnopqrstuvwxyzäö-\". The values should be the number of times the corresponding character appears in the word.\n",
        "\n",
        "Part 2.\n",
        "\n",
        "Write function `contains_valid_chars` that takes a string as a parameter and returns the truth value of whether all the characters in the string belong to the alphabet or not.\n",
        "\n",
        "Part 3.\n",
        "\n",
        "Write function `get_features_and_labels` that returns the tuple (X, y) of the feature matrix and the target vector. Use the labels 0 and 1 for Finnish and English, respectively. Use the supplied functions load_finnish() and load_english() to get the lists of words. Filter the lists in the following ways:\n",
        "\n",
        "* Convert the Finnish words to lowercase, and then filter out those words that contain characters that don't belong to the alphabet.\n",
        "* For the English words first filter out those words that begin with an uppercase letter to get rid of proper nouns. Then proceed as with the Finnish words.\n",
        "\n",
        "Use get_features function you made earlier to form the feature matrix.\n",
        "\n",
        "Part 4.\n",
        "\n",
        "We have earlier seen examples where we split the data into learning part and testing part. This way we can test whether the model can really be used to predict unseen data. However, it can be that we had bad luck and the split produced very biased learning and test datas. To counter this, we can perform the split several times and take as the final result the average from the different splits. This is called [cross validation](<https://en.wikipedia.org/wiki/Cross-validation_(statistics)>).\n",
        "\n",
        "Create `word_classification` function that does the following:\n",
        "\n",
        "Use the function `get_features_and_labels` you made earlier to get the feature matrix and the labels. Use multinomial naive Bayes to do the classification. Get the accuracy scores using the `sklearn.model_selection.cross_val_score` function; use 5-fold cross validation. The function should return a list of five accuracy scores.\n",
        "\n",
        "The cv parameter of `cross_val_score` can be either an integer, which specifies the number of folds, or it can be a *cross-validation generator* that generates the (train set,test set) pairs. What happens if you pass the following cross-validation generator to `cross_val_score` as a parameter: `sklearn.model_selection.KFold(n_splits=5, shuffle=True, random_state=0)`.\n",
        "\n",
        "Why the difference?\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So8CEGM23k3s",
        "colab_type": "text"
      },
      "source": [
        "#### <div class=\"alert alert-info\">Exercise 4 (spam detection)</div>\n",
        "\n",
        "This exercise gives two points if solved correctly!\n",
        "\n",
        "In the `src` folder there are two files: `ham.txt.gz` and `spam.txt.gz`. The files are preprocessed versions of the files from https://spamassassin.apache.org/old/publiccorpus/. There is one email per line. The file `ham.txt.gz` contains emails that are non-spam, and, conversely, emails in file `spam.txt` are spam. The email headers have been removed, except for the subject line, and non-ascii characters have been deleted.\n",
        "\n",
        "Write function `spam_detection` that does the following:\n",
        "\n",
        "* Read the lines from these files into arrays. Use function `open` from `gzip` module, since the files are compressed. From each file take only `fraction` of lines from the start of the file, where `fraction` is a parameter to `spam_detection`, and should be in the range `[0.0, 1.0]`.\n",
        "* forms the combined feature matrix using `CountVectorizer` class' `fit_transform` method. The feature matrix should first have the rows for the `ham` dataset and then the rows for the `spam` dataset. One row in the feature matrix corresponds to one email.\n",
        "* use labels 0 for ham and 1 for spam\n",
        "* divide that feature matrix and the target label into training and test sets, using `train_test_split`. Use 75% of the data for training. Pass the random_state parameter from `spam_detection` to `train_test_split`.\n",
        "* train a `MultinomialNB` model, and use it to predict the labels for the test set\n",
        "\n",
        "The function should return a triple consisting of\n",
        "\n",
        "* accuracy score of the prediction\n",
        "* size of test sample\n",
        "* number of misclassified sample points\n",
        "\n",
        "Note. The tests use the `fraction` parameter with value 0.1 to ease to load on the TMC server. If full data were used and the solution did something non-optimal, it could use huge amounts of memory, causing the solution to fail.\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmhzZ-3l3k3t",
        "colab_type": "text"
      },
      "source": [
        "<!--NAVIGATION-->\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/saskeli/x/blob/master/bayes.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
      ]
    }
  ]
}